# Etapas de Limepeza a serem seguidas:

<h3>Etapa 1: remover observações duplicadas ou irrelevantes: </h3>
<h4>Quando você combina conjuntos de dados de vários locais, coleta dados ou recebe dados de clientes ou vários departamentos, há oportunidades para criar dados duplicados. A desduplicação é uma das maiores áreas a serem consideradas nesse processo. Observações irrelevantes são quando você percebe observações que não se encaixam no problema específico que você está tentando analisar. Por exemplo, se você deseja analisar dados sobre clientes millennials, mas seu conjunto de dados inclui gerações mais antigas, remova essas observações irrelevantes. Isso pode tornar a análise mais eficiente e minimizar a distração do seu alvo principal</h4>
<hr>
<h3>Etapa 2: corrigir erros estruturais </h3>
<h4>Erros estruturais ocorrem quando você mede ou transfere dados e percebe convenções de nomenclatura estranhas, erros de digitação ou capitalização incorreta. Essas inconsistências podem causar categorias ou classes incorretas. Por exemplo, você pode descobrir que “N/A” e “Não aplicável” aparecem, mas devem ser analisados como a mesma categoria.</h4>
<hr>
<h3>Etapa 3: filtrar valores discrepantes indesejados </h3>
<h4>Muitas vezes, haverá observações pontuais em que, à primeira vista, elas não parecem se encaixar nos dados que você está analisando. Se você tiver um motivo legítimo para remover um outlier, como entrada inadequada de dados, isso ajudará no desempenho dos dados com os quais você está trabalhando. No entanto, às vezes é o aparecimento de um valor atípico que provará uma teoria na qual você está trabalhando. Lembre-se: só porque existe um outlier, não significa que esteja incorreto. Esta etapa é necessária para determinar a validade desse número. Se um outlier for irrelevante para análise ou for um erro, considere removê-lo.</h4>
<hr>
<h3>Etapa 4: lidar com dados ausentes</h3>
<h4>Você não pode ignorar dados ausentes porque muitos algoritmos não aceitam valores ausentes. Existem algumas maneiras de lidar com dados ausentes. Nenhum é o ideal, mas ambos podem ser considerados.<br>

Como primeira opção, você pode descartar observações com valores ausentes, mas fazer isso descartará ou perderá informações, portanto, lembre-se disso antes de removê-las.
Como segunda opção, você pode inserir valores ausentes com base em outras observações; novamente, há uma oportunidade de perder a integridade dos dados porque você pode estar operando a partir de suposições e não de observações reais.
Como uma terceira opção, você pode alterar a maneira como os dados são usados para navegar efetivamente por valores nulos.</h4>

<hr>
<h3>Etapa 5: valide e controle de qualidade</h3>
<h4>No final do processo de limpeza de dados, você deve ser capaz de responder a estas perguntas como parte da validação básica:<br>

- Os dados fazem sentido?
- Os dados seguem as regras apropriadas para seu campo?
- Isso prova ou refuta sua teoria de trabalho, ou traz algum insight à luz?
- Você pode encontrar tendências nos dados para ajudá-lo a formar sua próxima teoria?
- Se não, isso é devido a um problema de qualidade de dados?<br>

Conclusões falsas devido a dados incorretos ou “sujos” podem informar estratégias de negócios e tomadas de decisão ruins. Conclusões falsas podem levar a um momento embaraçoso em uma reunião de relatórios quando você percebe que seus dados não resistem ao escrutínio. Antes de chegar lá, é importante criar uma cultura de dados de qualidade em sua organização. Para fazer isso, você deve documentar as ferramentas que pode usar para criar essa cultura e o que a qualidade de dados significa para você.</h4>
